# Example Gallery
There are a lot of options for configuring cnn-vis; this page will show some examples to get you started.

## Target Layer
When making Inceptionism-style images, one of the most important parameters is the target layer. Using lower layers will tend to emphasize low-level image features, while higher layers will tend to emphasize object parts. As an example, we will start with Edvard Munch's classic painting ["The Scream"](https://en.wikipedia.org/wiki/The_Scream) and modify it using several different CNN layers:

<img src="http://cs.stanford.edu/people/jcjohns/cnn-vis-examples/initial-imgs/scream.jpg" width="400px">
<img src="http://cs.stanford.edu/people/jcjohns/cnn-vis-examples/example7.png" width="400px">
<img src="http://cs.stanford.edu/people/jcjohns/cnn-vis-examples/example8.png" width="400px">
<img src="http://cs.stanford.edu/people/jcjohns/cnn-vis-examples/example9.png" width="400px">

* **Upper left**: The original image.
* **Upper right**: Produced using the script [example7.sh](examples/example7.sh) which amplifies the relatively early `inception_3a/1x1` layer.
* **Lower left**: Produced using the script [example8.sh](examples/example8.sh) which amplifies the relatively early `inception_3a/3x3_reduce` layer.
* **Lower right**: Produced using the script [example9.sh](examples/example9.sh) which amplifies the later layer `inception_4d/output` layer, which is a bit later. Amplifying this layer causes animal parts to appear.

Here are a few more examples, using some of the same starting images as the original [Google blog post](http://googleresearch.blogspot.com/2015/06/inceptionism-going-deeper-into-neural.html):

<img src="http://cs.stanford.edu/people/jcjohns/cnn-vis-examples/example10.png" width="800px">

This one is generated by the script [example10.sh](examples/example10.sh).

<img src="http://cs.stanford.edu/people/jcjohns/cnn-vis-examples/example11.png" width="800px">

This one is generated by the script [example11.sh](examples/example11.sh). Note that for this example we made use of the auxiliary p-norm regularization; without it the region near the clouds tends to become oversaturated.

## Noise Initializations
Instead of starting with an existing image, you can also initialize using a random noise image. Here's an example, generated by the script [example2.sh](examples/example2.sh) which amplifies the `inception_4c/output` layer:

<img src="http://cs.stanford.edu/people/jcjohns/cnn-vis-examples/example2.png" width="800px">

Keep in mind that the output depends on the random noise used to initialize the image, so you may get a slightly different result if you rerun the script. It should however contain similar types of objects.

As we saw above, choosing different layers to amplify gives rise to different sorts of patterns; here's another exapmle generated by the script [example3.sh](examples/example3.sh):

<img src="http://cs.stanford.edu/people/jcjohns/cnn-vis-examples/example3.png" width="800px">

## Places CNN
In all of the examples so far, the underlying CNN was trained on the ImageNet dataset. If we use a CNN that was instead trained on the MIT places dataset, the generated images will tend to contain parts of buildings rather than parts of images. Here's an example, generated with the script [example5.sh](examples/example5.sh) which amplifies the `inception_4b/3x3_reduce` layer:

<img src="http://cs.stanford.edu/people/jcjohns/cnn-vis-examples/example5.png" width="800px">
